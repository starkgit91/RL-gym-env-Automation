{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8df7657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ae2be13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29adab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f19e6534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in d:\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: gymnasium in d:\\anaconda3\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\anaconda3\\lib\\site-packages (from gymnasium) (1.23.5)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from gymnasium) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from gymnasium) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in d:\\anaconda3\\lib\\site-packages (from gymnasium) (4.4.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in d:\\anaconda3\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: stable_baselines3 in d:\\anaconda3\\lib\\site-packages (2.0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: gymnasium==0.28.1 in d:\\anaconda3\\lib\\site-packages (from stable_baselines3) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\anaconda3\\lib\\site-packages (from stable_baselines3) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.11 in d:\\anaconda3\\lib\\site-packages (from stable_baselines3) (1.12.1)\n",
      "Requirement already satisfied: cloudpickle in d:\\anaconda3\\lib\\site-packages (from stable_baselines3) (2.0.0)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (from stable_baselines3) (1.5.3)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda3\\lib\\site-packages (from stable_baselines3) (3.7.0)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from gymnasium==0.28.1->stable_baselines3) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in d:\\anaconda3\\lib\\site-packages (from gymnasium==0.28.1->stable_baselines3) (4.4.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in d:\\anaconda3\\lib\\site-packages (from gymnasium==0.28.1->stable_baselines3) (0.0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda3\\lib\\site-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\lib\\site-packages (from pandas->stable_baselines3) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install stable_baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d05cea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e7c59e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=\"human\", size=5):\n",
    "        self.size = size  # The size of the square grid\n",
    "        self.window_size = 512  # The size of the PyGame window\n",
    "\n",
    "        # Observations are dictionaries with the agent's and the target's location.\n",
    "        # Each location is encoded as an element of {0, ..., `size`}^2, i.e. MultiDiscrete([size, size]).\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                \"agent\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "                \"target\": spaces.Box(0, size - 1, shape=(2,), dtype=int),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # We have 4 actions, corresponding to \"right\", \"up\", \"left\", \"down\"\n",
    "        self.action_space = spaces.Discrete(8,start=1)\n",
    "\n",
    "        \"\"\"\n",
    "        The following dictionary maps abstract actions from `self.action_space` to\n",
    "        the direction we will walk in if that action is taken.\n",
    "        I.e. 0 corresponds to \"right\", 1 to \"up\" etc.\n",
    "        \"\"\"\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([-1, 0]),\n",
    "            1: np.array([0, -1]),\n",
    "            2: np.array([1, 0]),\n",
    "            3: np.array([0, 1]),\n",
    "            4: np.array([1,-1]),\n",
    "            5: np.array([1,1]),\n",
    "            6: np.array([-1,1]),\n",
    "            7: np.array([-1,-1]),\n",
    "            8: np.array([0,0])\n",
    "        }\n",
    "\n",
    "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        \"\"\"\n",
    "        If human-rendering is used, `self.window` will be a reference\n",
    "        to the window that we draw to. `self.clock` will be a clock that is used\n",
    "        to ensure that the environment is rendered at the correct framerate in\n",
    "        human-mode. They will remain `None` until human-mode is used for the\n",
    "        first time.\n",
    "        \"\"\"\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        # Map the action (element of {0,1,2,3}) to the direction we walk in\n",
    "        direction = self._action_to_direction[action]\n",
    "        self._agent_location = np.clip(\n",
    "            self._agent_location + direction, 0, self.size - 1\n",
    "        )\n",
    "        # An episode is done iff the agent has reached the target\n",
    "        terminated = np.array_equal(self._agent_location, self._target_location)\n",
    "        reward = 1 if terminated else -1  # Binary sparse rewards\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, reward, terminated, False, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\"agent\": self._agent_location, \"target\": self._target_location}\n",
    "\n",
    "# %%\n",
    "# We can also implement a similar method for the auxiliary information\n",
    "# that is returned by ``step`` and ``reset``. In our case, we would like\n",
    "# to provide the manhattan distance between the agent and the target:\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {\n",
    "            \"distance\": np.linalg.norm(\n",
    "                self._agent_location - self._target_location, ord=1\n",
    "            )\n",
    "        }\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        # We need the following line to seed self.np_random\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Choose the agent's location uniformly at random\n",
    "        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n",
    "\n",
    "        # We will sample the target's location randomly until it does not coincide with the agent's location\n",
    "        self._target_location = self._agent_location\n",
    "        while np.array_equal(self._target_location, self._agent_location):\n",
    "            self._target_location = self.np_random.integers(\n",
    "                0, self.size, size=2, dtype=int\n",
    "            )\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size, self.window_size)\n",
    "            )\n",
    "        if self.clock is None and self.render_mode == \"human\":\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
    "        canvas.fill((255, 255, 255))\n",
    "        pix_square_size = (\n",
    "            self.window_size / self.size\n",
    "        )  # The size of a single grid square in pixels\n",
    "\n",
    "        # First we draw the target\n",
    "        pygame.draw.rect(\n",
    "            canvas,\n",
    "            (255, 0, 0),\n",
    "            pygame.Rect(\n",
    "                pix_square_size * self._target_location,\n",
    "                (pix_square_size, pix_square_size),\n",
    "            ),\n",
    "        )\n",
    "        # Now we draw the agent\n",
    "        pygame.draw.circle(\n",
    "            canvas,\n",
    "            (0, 0, 255),\n",
    "            (self._agent_location + 0.5) * pix_square_size,\n",
    "            pix_square_size / 3,\n",
    "        )\n",
    "\n",
    "        # Finally, add some gridlines\n",
    "        for x in range(self.size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (0, pix_square_size * x),\n",
    "                (self.window_size, pix_square_size * x),\n",
    "                width=3,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                0,\n",
    "                (pix_square_size * x, 0),\n",
    "                (pix_square_size * x, self.window_size),\n",
    "                width=3,\n",
    "            )\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            # The following line copies our drawings from `canvas` to the visible window\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            # We need to ensure that human-rendering occurs at the predefined framerate.\n",
    "            # The following line will automatically add a delay to keep the framerate stable.\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n",
    "# In many cases, you don’t actually have to bother to\n",
    "# implement this method. However, in our example ``render_mode`` may be\n",
    "# ``\"human\"`` and we might need to close the window that has been opened:\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45af590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in d:\\anaconda3\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in d:\\anaconda3\\lib\\site-packages (from gym) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in d:\\anaconda3\\lib\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: shimmy in d:\\anaconda3\\lib\\site-packages (1.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.18.0 in d:\\anaconda3\\lib\\site-packages (from shimmy) (1.23.5)\n",
      "Requirement already satisfied: gymnasium>=0.27.0 in d:\\anaconda3\\lib\\site-packages (from shimmy) (0.28.1)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from gymnasium>=0.27.0->shimmy) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from gymnasium>=0.27.0->shimmy) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in d:\\anaconda3\\lib\\site-packages (from gymnasium>=0.27.0->shimmy) (4.4.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in d:\\anaconda3\\lib\\site-packages (from gymnasium>=0.27.0->shimmy) (0.0.4)\n"
     ]
    }
   ],
   "source": [
    "pip install shimmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e7e443b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent': array([0, 4]), 'target': array([1, 2])}, {'distance': 3.0})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = GridWorldEnv()\n",
    "dic = env.reset()\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd248277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent': array([0, 4]), 'target': array([1, 2])},\n",
       " -1,\n",
       " False,\n",
       " False,\n",
       " {'distance': 3.0})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(2)\n",
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c4fe9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent': array([0, 4]), 'target': array([0, 0])}, {'distance': 4.0})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "obs, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "381d8305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent': array([0, 3]), 'target': array([0, 0])},\n",
       " -1,\n",
       " False,\n",
       " False,\n",
       " {'distance': 3.0})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)\n",
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aacfcf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING DQN(Deep Queue Network) RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7254c05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 61       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 192      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 718      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.38     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 979      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.104    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 1415     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 430      |\n",
      "|    total_timesteps  | 1687     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 473      |\n",
      "|    total_timesteps  | 1854     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 521      |\n",
      "|    total_timesteps  | 2045     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 669      |\n",
      "|    total_timesteps  | 2629     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 701      |\n",
      "|    total_timesteps  | 2755     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 783      |\n",
      "|    total_timesteps  | 3076     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 792      |\n",
      "|    total_timesteps  | 3107     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 824      |\n",
      "|    total_timesteps  | 3230     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 841      |\n",
      "|    total_timesteps  | 3297     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 907      |\n",
      "|    total_timesteps  | 3554     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 990      |\n",
      "|    total_timesteps  | 3883     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1006     |\n",
      "|    total_timesteps  | 3941     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1109     |\n",
      "|    total_timesteps  | 4348     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1161     |\n",
      "|    total_timesteps  | 4554     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1201     |\n",
      "|    total_timesteps  | 4708     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1269     |\n",
      "|    total_timesteps  | 4974     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1315     |\n",
      "|    total_timesteps  | 5155     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 3        |\n",
      "|    time_elapsed     | 1388     |\n",
      "|    total_timesteps  | 5442     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m DQN(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdqn_grid_world\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDQN,\n\u001b[0;32m    260\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDQN:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:312\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    309\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 312\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:544\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    541\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[0;32m    543\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    547\u001b[0m num_collected_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "Cell \u001b[1;32mIn[81], line 64\u001b[0m, in \u001b[0;36mGridWorldEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     61\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_info()\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation, reward, terminated, \u001b[38;5;28;01mFalse\u001b[39;00m, info\n",
      "Cell \u001b[1;32mIn[81], line 169\u001b[0m, in \u001b[0;36mGridWorldEnv._render_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# We need to ensure that human-rendering occurs at the predefined framerate.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# The following line will automatically add a delay to keep the framerate stable.\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# rgb_array\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[0;32m    172\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mpixels3d(canvas)), axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    173\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.stdout = sys.stdout.bufferimport gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "# env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "\n",
    "# Create the environment\n",
    "env = GridWorldEnv()\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Create the DQN model\n",
    "model = DQN(\"MultiInputPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=15000, log_interval=4)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"dqn_grid_world\")\n",
    "\n",
    "# Load the model\n",
    "model = DQN.load(\"dqn_grid_world\")\n",
    "\n",
    "obs, info = env.reset()\n",
    "x = input(\"enter random input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6579440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n",
      "{'agent': array([0, 4]), 'target': array([1, 4])} -1 False False {'distance': 1.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m int_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(action)\n\u001b[1;32m----> 7\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mint_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(obs, reward, terminated, truncated, info)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "Cell \u001b[1;32mIn[81], line 64\u001b[0m, in \u001b[0;36mGridWorldEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     61\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_info()\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation, reward, terminated, \u001b[38;5;28;01mFalse\u001b[39;00m, info\n",
      "Cell \u001b[1;32mIn[81], line 169\u001b[0m, in \u001b[0;36mGridWorldEnv._render_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# We need to ensure that human-rendering occurs at the predefined framerate.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# The following line will automatically add a delay to keep the framerate stable.\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# rgb_array\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[0;32m    172\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mpixels3d(canvas)), axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    173\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Continue interacting with the environment using the trained model\n",
    "env = GridWorldEnv()\n",
    "obs, info = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    int_action = int(action)\n",
    "    obs, reward, terminated, truncated, info = env.step(int_action)\n",
    "    print(obs, reward, terminated, truncated, info)\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58e331f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6de15dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Automation by hard Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6084a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_dict = dict(dic.__getitem__(0))\n",
    "# print(pos_dict)\n",
    "# dist_dict = dict(dic.__getitem__(1))\n",
    "# print(dist_dict)\n",
    "# from numpy import array as arr\n",
    "# pos_agent = arr(pos_dict.get('agent'))\n",
    "# pos_target = arr(pos_dict.get('target'))\n",
    "# print(pos_agent, pos_target)\n",
    "# distance_agent_target = dist_dict.get('distance')\n",
    "# print(int(distance_agent_target))\n",
    "# vector = [int(abs(pos_agent[0]-pos_target[0])),int(abs(pos_agent[1]-pos_target[1]))]\n",
    "# vec1 = vector[0]\n",
    "# vec2 = vector[1]\n",
    "# if(pos_target[0] != pos_agent[0]):\n",
    "#     if(pos_target[0]<pos_agent[0]):\n",
    "#         while(vec1!=0):\n",
    "#             env.step(0)\n",
    "#             vec1 -= 1\n",
    "#     else:\n",
    "#         while(vec1!=0):\n",
    "#             env.step(2)\n",
    "#             vec1 -= 1\n",
    "\n",
    "# if(pos_target[1] != pos_agent[1]):\n",
    "#     if(pos_target[1]<pos_agent[1]):\n",
    "#         while(vec2!=0):\n",
    "#             env.step(1)\n",
    "#             vec2 -= 1\n",
    "#     else:\n",
    "#         while(vec2!=0):\n",
    "#             env.step(3)\n",
    "#             vec2 -= 1\n",
    "\n",
    "# print(env._get_obs(),env._get_info())\n",
    "# # env.step(0)\n",
    "# # env.step(1)\n",
    "# # env.step(2)\n",
    "# # env.step(3)\n",
    "# # env.step(4)\n",
    "# # env.step(5)\n",
    "# # env.step(6)\n",
    "# # env.step(1)\n",
    "# # if(pos_target[1] != pos_agent[1]):\n",
    "# #     env.step(pos_target[1])\n",
    "# # env.render()\n",
    "# # env._render_frame()\n",
    "# import time as stark\n",
    "# stark.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad798aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING A2C RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec922c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calling torch.geqrf on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Parallel environments\u001b[39;00m\n\u001b[0;32m      5\u001b[0m vec_env \u001b[38;5;241m=\u001b[39m env \u001b[38;5;66;03m#make_vec_env(env, n_envs=4)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mA2C\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultiInputPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvec_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25000\u001b[39m)\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma2c_grid_world\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:123\u001b[0m, in \u001b[0;36mA2C.__init__\u001b[1;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, rms_prop_eps, use_rms_prop, use_sde, sde_sample_freq, normalize_advantage, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99\u001b[39m, eps\u001b[38;5;241m=\u001b[39mrms_prop_eps, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _init_setup_model:\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:123\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm._setup_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrollout_buffer \u001b[38;5;241m=\u001b[39m buffer_cls(\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps,\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m     n_envs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_envs,\n\u001b[0;32m    121\u001b[0m )\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# pytype:disable=not-instantiable\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_class(  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_schedule, use_sde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_sde, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_kwargs\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# pytype:enable=not-instantiable\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:853\u001b[0m, in \u001b[0;36mMultiInputActorCriticPolicy.__init__\u001b[1;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    835\u001b[0m     observation_space: spaces\u001b[38;5;241m.\u001b[39mDict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    851\u001b[0m     optimizer_kwargs: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    852\u001b[0m ):\n\u001b[1;32m--> 853\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnet_arch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m        \u001b[49m\u001b[43mortho_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_std_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_expln\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43msquash_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_extractor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_features_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:507\u001b[0m, in \u001b[0;36mActorCriticPolicy.__init__\u001b[1;34m(self, observation_space, action_space, lr_schedule, net_arch, activation_fn, ortho_init, use_sde, log_std_init, full_std, use_expln, squash_output, features_extractor_class, features_extractor_kwargs, share_features_extractor, normalize_images, optimizer_class, optimizer_kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# Action distribution\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist \u001b[38;5;241m=\u001b[39m make_proba_distribution(action_space, use_sde\u001b[38;5;241m=\u001b[39muse_sde, dist_kwargs\u001b[38;5;241m=\u001b[39mdist_kwargs)\n\u001b[1;32m--> 507\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:603\u001b[0m, in \u001b[0;36mActorCriticPolicy._build\u001b[1;34m(self, lr_schedule)\u001b[0m\n\u001b[0;32m    600\u001b[0m         module_gains[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf_features_extractor] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module, gain \u001b[38;5;129;01min\u001b[39;00m module_gains\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 603\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# Setup optimizer with initial learning rate\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_class(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr_schedule(\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:668\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03mas well as self. Typical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m(see also :ref:`nn-init-doc`).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m    )\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 668\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    669\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:668\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;124;03mas well as self. Typical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m(see also :ref:`nn-init-doc`).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m    )\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 668\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    669\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:669\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m    668\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[1;32m--> 669\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:306\u001b[0m, in \u001b[0;36mBasePolicy.init_weights\u001b[1;34m(module, gain)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03mOrthogonal initialization (used in PPO and A2C)\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, (nn\u001b[38;5;241m.\u001b[39mLinear, nn\u001b[38;5;241m.\u001b[39mConv2d)):\n\u001b[1;32m--> 306\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morthogonal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m         module\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m0.0\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\init.py:483\u001b[0m, in \u001b[0;36morthogonal_\u001b[1;34m(tensor, gain)\u001b[0m\n\u001b[0;32m    480\u001b[0m     flattened\u001b[38;5;241m.\u001b[39mt_()\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# Compute the qr factorization\u001b[39;00m\n\u001b[1;32m--> 483\u001b[0m q, r \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf\u001b[39;00m\n\u001b[0;32m    485\u001b[0m d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(r, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calling torch.geqrf on a CPU tensor requires compiling PyTorch with LAPACK. Please use PyTorch built with LAPACK support."
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "env = GridWorldEnv()\n",
    "# Parallel environments\n",
    "vec_env = env #make_vec_env(env, n_envs=4)\n",
    "\n",
    "model = A2C(\"MultiInputPolicy\", vec_env, verbose=1)\n",
    "model.learn(total_timesteps=25000)\n",
    "model.save(\"a2c_grid_world\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = A2C.load(\"a2c_grid_world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3602a480",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'a2c_grid_world.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mA2C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma2c_grid_world\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m obs, info \u001b[38;5;241m=\u001b[39m vec_env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:679\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    677\u001b[0m     get_system_info()\n\u001b[1;32m--> 679\u001b[0m data, params, pytorch_variables \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo params found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:390\u001b[0m, in \u001b[0;36mload_from_zip_file\u001b[1;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_zip_file\u001b[39m(\n\u001b[0;32m    364\u001b[0m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath, io\u001b[38;5;241m.\u001b[39mBufferedIOBase],\n\u001b[0;32m    365\u001b[0m     load_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m     print_system_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    370\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m     load_path \u001b[38;5;241m=\u001b[39m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\functools.py:889\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    887\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:234\u001b[0m, in \u001b[0;36mopen_path_str\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;129m@open_path\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedIOBase:\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03m    that the path exists.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\functools.py:889\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    887\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:286\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    279\u001b[0m         path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# if opening was successful uses the identity function\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\functools.py:889\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    887\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:266\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    264\u001b[0m             path, suffix \u001b[38;5;241m=\u001b[39m newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:258\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[1;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 258\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\pathlib.py:1119\u001b[0m, in \u001b[0;36mPath.open\u001b[1;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1118\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m-> 1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'a2c_grid_world.zip'"
     ]
    }
   ],
   "source": [
    "model = A2C.load(\"a2c_grid_world\")\n",
    "obs, info = vec_env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs,deterministic=True)\n",
    "    int_action = int(action)\n",
    "    obs, rewards, dones, info = vec_env.step(int_action)\n",
    "    vec_env.render(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d84c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
